import faiss
import numpy as np
import pdfplumber
from sentence_transformers import SentenceTransformer
from transformers import pipeline
import os
import warning

# Step 1: Extract text from PDF using pdfplumber
def extract_text_from_pdf(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        text = ""
        for page in pdf.pages:
            text += page.extract_text()
    return text

# Step 2: Initialize SentenceTransformer model and FAISS index
def initialize_faiss_index(text):
    model = SentenceTransformer('all-MiniLM-L6-v2')  # Load a pre-trained sentence transformer
    sentences = text.split('\n')  # Split text into sentences or paragraphs
    embeddings = model.encode(sentences, convert_to_numpy=True)  # Create embeddings for each sentence
    
    # Initialize FAISS index
    index = faiss.IndexFlatL2(embeddings.shape[1])  # L2 distance metric for similarity search
    index.add(np.array(embeddings))  # Add embeddings to the index
    return model, sentences, index

# Step 3: Retrieve relevant passages based on a query
def retrieve_relevant_passages(query, model, sentences, index, k=3):
    query_embedding = model.encode([query], convert_to_numpy=True)  # Create query embedding
    distances, indices = index.search(query_embedding, k)  # Retrieve top-k similar sentences
    retrieved_passages = [sentences[idx] for idx in indices[0]]
    return retrieved_passages

# Step 4: Generate a response using GPT-3 or similar model
def generate_response(query, relevant_passages):
    context = " ".join(relevant_passages)  # Concatenate retrieved passages
    generator = pipeline("text-generation", model="gpt-2")  # Using GPT-2 for generation (you can switch to GPT-3)
    response = generator(f"Context: {context} \nQuestion: {query} \nAnswer:", max_length=200)
    return response[0]['generated_text']

# Step 5: Main function to chat with PDF
def chat_with_pdf(pdf_path, query):
    # Step 1: Extract text from the PDF
    pdf_text = extract_text_from_pdf(pdf_path)

    # Step 2: Initialize FAISS index
    model, sentences, index = initialize_faiss_index(pdf_text)

    # Step 3: Retrieve relevant passages
    relevant_passages = retrieve_relevant_passages(query, model, sentences, index)

    # Step 4: Generate and return response
    response = generate_response(query, relevant_passages)
    return response

# Example usage
if __name__ == "__main__":
    pdf_path = "file:///C:/Users/DELL/Desktop/gopitask1/Sithafal%20-%20project-tasks.pdf"  # Path to the PDF
    query = "What is the main purpose of this document?"  # Your query to the PDF
    response = chat_with_pdf(pdf_path, query)
    print(response)
